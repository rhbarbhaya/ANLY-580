---
title: "9 MTMM"
author: "Rushabh Barbhaya"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## MTMM Practice Assignment

In this example, we will expand our previous example to include one more measurement method of meaning and purpose. The data includes three scales that measure meaning and purpose: The Meaning in Life Questionnaire, the Purpose in Life Questionnaire, and the Seeking of Noetic Goals test. The mapping of traits and methods are:

- Traits:
    - Meaning: 
        - MLQ 1, 2, 5, 10
        - SONG 1, 9
        - PIL 4, 17
    - Purpose:
        - MLQ 3, 4, 6, 8, 9
        - SONG 2, 8
        - PIL 3, 20
- Methods
    - MLQ (m questions)
    - SONG (s questions)
    - PIL (p questions)

## Data and Libraries

Import the data and libraries you need below.

```{r}
library(rio)
library(lavaan)
library(semPlot)

data = import('assignment_mtmm.csv')
names(data)
```

## Model 1

In this section, build, analyze, and summarize model 1. You can include a diagram if you like, but we will mainly focus on the model building, `cfa()`, and `summary()` in this assignment. 

```{r}
modelone = '
mlq =~ m1 + m2 + m5 + m10 + m3 + m4 + m6 + m8 + m9
pil =~ p4 + p17 + p3 + p20
song =~ s1 + s9 + s2 + s8
meaning =~ m1 + m2 + m5 + m10 + s1 + s9 + p4 + p17
purpose =~ m3 + m4 + m6 + m8 + m9 + s2 + s8 + p3 + p20
mlq ~~ 0*meaning
pil ~~ 0*meaning
song ~~ 0*meaning
mlq ~~ 0*purpose
pil ~~ 0*purpose
song ~~ 0*purpose
'

modelone.fit = cfa(model = modelone, data = data, std.lv = T)
summary(modelone.fit, standardized = T, rsquare = T, fit.measures = T)
```

## Model 2

In this section, build, analyze, and summarize model 2 for the methods only model. 

```{r}
modeltwo = '
mlq =~ m1 + m2 + m5 + m10 + m3 + m4 + m6 + m8 + m9
pil =~ p4 + p17 + p3 + p20
song =~ s1 + s9 + s2 + s8
'

modeltwo.fit = cfa(model = modeltwo, data = data, std.lv = T)
summary(modeltwo.fit, standardized = T, rsquare = T, fit.measures = T)
```

## Model 3

In this section, build, analyze, and summarize model 3 for the perfectly correlated traits model. 

```{r}
modelthree = '
mlq =~ m1 + m2 + m5 + m10 + m3 + m4 + m6 + m8 + m9
pil =~ p4 + p17 + p3 + p20
song =~ s1 + s9 + s2 + s8
meaning =~ m1 + m2 + m5 + m10 + s1 + s9 + p4 + p17
purpose =~ m3 + m4 + m6 + m8 + m9 + s2 + s8 + p3 + p20
mlq ~~ 0*meaning
pil ~~ 0*meaning
song ~~ 0*meaning
mlq ~~ 0*purpose
pil ~~ 0*purpose
song ~~ 0*purpose
meaning ~~ 1*purpose
'

modelthree.fit = cfa(model = modelthree, data = data, std.lv = T)
summary(modelthree.fit, standardized = T, rsquare = T, fit.measures = T)
```

## Model 4

In this section, build, analyze, and summarize model 4 for the uncorrelated methods model. 

```{r}
modelfour = '
mlq =~ m1 + m2 + m5 + m10 + m3 + m4 + m6 + m8 + m9
pil =~ p4 + p17 + p3 + p20
song =~ s1 + s9 + s2 + s8
meaning =~ m1 + m2 + m5 + m10 + s1 + s9 + p4 + p17
purpose =~ m3 + m4 + m6 + m8 + m9 + s2 + s8 + p3 + p20
mlq ~~ 0*meaning
pil ~~ 0*meaning
song ~~ 0*meaning
mlq ~~ 0*purpose
pil ~~ 0*purpose
song ~~ 0*purpose
mlq ~~ 0*pil
mlq ~~ 0*song
pil ~~ 0*song
'

modelfour.fit = cfa(model = modelfour, data = data, std.lv = T)
summary(modelfour.fit, standardized = T, rsquare = T, fit.measures = T)
```

## Comparisons

We can use `kable()` from the `knitr` library to help us build a table to compare models. You will want to change the `1:5` to the appropriate model step using `fitmeasures` to grab the fit statistics mentioned. An example is provided below. There are lots of ways to make these types of tables, including `broom`. Additionally, `flextable` is a great table package as well. Here's just an example of how one might summarize their models. 

```{r model_table, results = 'asis'}
library(knitr)
tableprint <- matrix(NA, nrow = 4, ncol = 6)
colnames(tableprint) <- c("Model", "Chi-Square", "df", 
                         "RMSEA", "SRMR", "CFI")
##replace the 1:5 with the appropriate code
##the code should be fitmeasures(step1.fit, c("chisq", "df", "rmsea", "srmr", "cfi"))
##add that code for each section
tableprint[1, ] = c("Model 1 - Correlated traits and methods", round(fitmeasures(modelone.fit, c("chisq", "df", "rmsea", "srmr", "cfi")),3))
tableprint[2, ] = c("Model 2 - No traits, correlated methods", round(fitmeasures(modeltwo.fit, c("chisq", "df", "rmsea", "srmr", "cfi")),3))
tableprint[3, ] = c("Model 3 - Perfectly correlated traits, correlated methods", round(fitmeasures(modelthree.fit, c("chisq", "df", "rmsea", "srmr", "cfi")),3))
tableprint[4, ] = c("Model 4 - Correlated traits, uncorrelated methods", round(fitmeasures(modelfour.fit, c("chisq", "df", "rmsea", "srmr", "cfi")),3))

kable(tableprint)
```

QUESTION: Using CFI change, what do the model results suggest? For each step note if the models are different, and if that supports/does not support convergent and divergent validity. 
ANSWER MODEL 1 VERSUS MODEL 2: Model 1 supports convergent validity
ANSWER MODEL 1 VERSUS MODEL 3: Model 1 and Model 3 have same scores. Doesn't support validity
ANSWER MODEL 1 VERSUS MODEL 4: Model 1 and Model 4 are have some differnt score, Model 1 being better. Therefore, doesn't support divergent validity

## Interpreting Parmaters

Print out the `parameterestimates` for Model 1. 

```{r}
parameterestimates(modelone.fit, standardized = T)
```

QUESTION: Are the parameter estimates for the traits higher than the ones for the methods? 
ANSWER: Half and Half. Some variances are on methods and some on traits.

QUESTION: Examine the correlations between traits. Do the correlations support divergent validity of the traits? 
ANSWER: No. Correlation value are almost 1

QUESTION: Examine the correlation between the methods. Do the correlations support the divergent validity of the methods?
ANSWER: MLQ ~~ Song are fairly correlated. PIL is good.